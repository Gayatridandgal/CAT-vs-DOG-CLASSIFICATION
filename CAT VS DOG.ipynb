{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4510e09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/datasets/abhinavnayak/catsvdogs-transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b166995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense,Conv2D, MaxPooling2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5892c374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/abhinavnayak/catsvdogs-transformed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/16.6M [00:00<?, ?B/s]\n",
      "  6%|6         | 1.00M/16.6M [00:01<00:17, 935kB/s]\n",
      " 12%|#2        | 2.00M/16.6M [00:01<00:14, 1.09MB/s]\n",
      " 18%|#8        | 3.00M/16.6M [00:02<00:11, 1.23MB/s]\n",
      " 24%|##4       | 4.00M/16.6M [00:03<00:09, 1.38MB/s]\n",
      " 30%|###       | 5.00M/16.6M [00:03<00:08, 1.48MB/s]\n",
      " 36%|###6      | 6.00M/16.6M [00:04<00:07, 1.57MB/s]\n",
      " 42%|####2     | 7.00M/16.6M [00:05<00:05, 1.71MB/s]\n",
      " 48%|####8     | 8.00M/16.6M [00:05<00:05, 1.51MB/s]\n",
      " 54%|#####4    | 9.00M/16.6M [00:06<00:05, 1.52MB/s]\n",
      " 60%|######    | 10.0M/16.6M [00:07<00:04, 1.51MB/s]\n",
      " 66%|######6   | 11.0M/16.6M [00:08<00:04, 1.34MB/s]\n",
      " 72%|#######2  | 12.0M/16.6M [00:08<00:03, 1.36MB/s]\n",
      " 78%|#######8  | 13.0M/16.6M [00:11<00:04, 870kB/s] \n",
      " 84%|########4 | 14.0M/16.6M [00:11<00:02, 986kB/s]\n",
      " 90%|######### | 15.0M/16.6M [00:12<00:01, 1.05MB/s]\n",
      " 97%|#########6| 16.0M/16.6M [00:13<00:00, 1.13MB/s]\n",
      "100%|##########| 16.6M/16.6M [00:14<00:00, 1.11MB/s]\n",
      "100%|##########| 16.6M/16.6M [00:14<00:00, 1.23MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "License(s): CC0-1.0\n",
      "Downloading catsvdogs-transformed.zip to C:\\Users\\Acer\\4-SEM\\A_internship\\BHARAT INTERN\\CAT vs DOG\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d abhinavnayak/catsvdogs-transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8ca955c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Provide the filename of your ZIP file\n",
    "zip_filename = 'catsvdogs-transformed.zip'\n",
    "\n",
    "# Construct the full path to the ZIP file\n",
    "zip_path = os.path.join(current_dir, zip_filename)\n",
    "\n",
    "# Open the ZIP file in read mode\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    # Extract all the contents to the specified directory\n",
    "    zip_ref.extractall('/content')\n",
    "\n",
    "print(\"Extraction completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d6c5f79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 1 classes.\n",
      "Found 2000 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# generators\n",
    "train_ds = keras.utils.image_dataset_from_directory(\n",
    "    \n",
    "    directory = r\"C:\\Users\\Acer\\4-SEM\\A_internship\\BHARAT INTERN\\CAT vs DOG\\catsvdogs-transformed\",\n",
    "    labels='inferred',\n",
    "    label_mode = 'int',\n",
    "    batch_size=32,\n",
    "    image_size=(256,256)\n",
    ")\n",
    "\n",
    "validation_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory = r\"C:\\Users\\Acer\\4-SEM\\A_internship\\BHARAT INTERN\\CAT vs DOG\\catsvdogs-transformed\",\n",
    "    labels='inferred',\n",
    "    label_mode = 'int',\n",
    "    batch_size=32,\n",
    "    image_size=(256,256)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cba9ae",
   "metadata": {},
   "source": [
    "# Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9f7d5ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Normalize\n",
    "def process(image,label):\n",
    "    image = tf.cast(image/255. ,tf.float32)\n",
    "    return image,label\n",
    "\n",
    "train_ds = train_ds.map(process)\n",
    "validation_ds = validation_ds.map(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "452a08a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# create CNN model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding='valid',activation='relu',input_shape=(256,256,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
    "\n",
    "model.add(Conv2D(64,kernel_size=(3,3),padding='valid',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
    "\n",
    "model.add(Conv2D(128,kernel_size=(3,3),padding='valid',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128,activation='relu'))\n",
    "\n",
    "model.add(Dense(64,activation='relu'))\n",
    "\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "38fc3bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6621c98a",
   "metadata": {},
   "source": [
    "# Training and Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210a46e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 0.0474 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 2/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m618s\u001b[0m 10s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 7/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 5s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 9/10\n",
      "\u001b[1m26/63\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:42\u001b[0m 4s/step - accuracy: 1.0000 - loss: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds,epochs=10,validation_data=validation_ds)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb612e01",
   "metadata": {},
   "source": [
    "# Graphical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20af561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'],color='red',label='train')\n",
    "plt.plot(history.history['val_accuracy'],color='blue',label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3306502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.plot(history.history['accuracy'],color='red',label='train')\n",
    "plt.plot(history.history['val_accuracy'],color='blue',label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b35be50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.plot(history.history['loss'],color='red',label='train')\n",
    "plt.plot(history.history['val_loss'],color='blue',label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d952deb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.plot(history.history['loss'],color='red',label='train')\n",
    "plt.plot(history.history['val_loss'],color='blue',label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84df788",
   "metadata": {},
   "source": [
    "Reduce Overfitting Techniques used# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b312e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding='valid',activation='relu',input_shape=(256,256,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
    "\n",
    "model.add(Conv2D(64,kernel_size=(3,3),padding='valid',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
    "\n",
    "model.add(Conv2D(128,kernel_size=(3,3),padding='valid',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95f7572",
   "metadata": {},
   "source": [
    "# Training and Testing(Again)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba9d4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2d785d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds,epochs=10,validation_data=validation_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f4423c",
   "metadata": {},
   "source": [
    "# Image importing for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a02c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = cv2.imread('/content/dog.jpg')\n",
    "plt.imshow(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6530ebf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05af3d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_img = cv2.resize(test_img,(256,256))\n",
    "test_input = test_img.reshape((1,256,256,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8608ccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = model.predict(test_input)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bc98d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if mod == 0:\n",
    "  print(\"Model Predicted image as Cat\")\n",
    "else:\n",
    "  print(\"Model Predicted image as Dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f44cabe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc3b368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d6d505",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
